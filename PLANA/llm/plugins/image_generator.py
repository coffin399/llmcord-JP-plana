from __future__ import annotations

import asyncio
import base64
import io
import logging
from typing import Dict, Any, Optional, List

import aiohttp
import discord

logger = logging.getLogger(__name__)


class ImageGenerator:
    """ÁîªÂÉèÁîüÊàê„Éó„É©„Ç∞„Ç§„É≥ - Hugging Face Inference Providers / NVIDIA NIMÂØæÂøú"""

    def __init__(self, bot):
        self.bot = bot
        self.config = bot.config.get('llm', {})
        self.image_gen_config = self.config.get('image_generator', {})

        # „Éá„Éï„Ç©„É´„ÉàË®≠ÂÆö
        self.default_model = self.image_gen_config.get('model', 'huggingface/stabilityai/stable-diffusion-xl-base-1.0')
        self.default_size = self.image_gen_config.get('default_size', '1024x1024')
        self.timeout = self.image_gen_config.get('timeout', 120.0)

        # Âà©Áî®ÂèØËÉΩ„Å™„É¢„Éá„É´„É™„Çπ„Éà
        self.available_models = self.image_gen_config.get('available_models', [self.default_model])
        if self.default_model not in self.available_models:
            self.available_models.insert(0, self.default_model)
            logger.warning(f"Default model '{self.default_model}' not in available_models, adding it")

        # „Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö
        self.image_providers = self.image_gen_config.get('image_providers', {})
        self.llm_providers = self.config.get('providers', {})

        # „ÉÅ„É£„É≥„Éç„É´„Åî„Å®„ÅÆ„É¢„Éá„É´Ë®≠ÂÆö
        self.channel_models_path = "data/channel_image_models.json"
        self.channel_models: Dict[str, str] = self._load_channel_models()

        self.http_session = aiohttp.ClientSession()

        logger.info(f"ImageGenerator initialized with default model: {self.default_model}")
        logger.info(f"Available image models: {len(self.available_models)} models")
        logger.info(f"Configured providers: {list(self.image_providers.keys())}")

    def _load_channel_models(self) -> Dict[str, str]:
        """„ÉÅ„É£„É≥„Éç„É´„Åî„Å®„ÅÆ„É¢„Éá„É´Ë®≠ÂÆö„ÇíË™≠„ÅøËæº„ÇÄ"""
        import os
        import json

        if os.path.exists(self.channel_models_path):
            try:
                with open(self.channel_models_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    logger.info(f"Loaded {len(data)} channel-specific image model settings")
                    return {str(k): v for k, v in data.items()}
            except Exception as e:
                logger.error(f"Failed to load channel image models: {e}")
        return {}

    async def _save_channel_models(self) -> None:
        """„ÉÅ„É£„É≥„Éç„É´„Åî„Å®„ÅÆ„É¢„Éá„É´Ë®≠ÂÆö„Çí‰øùÂ≠ò"""
        import os
        import json

        try:
            os.makedirs(os.path.dirname(self.channel_models_path), exist_ok=True)

            try:
                import aiofiles
                async with aiofiles.open(self.channel_models_path, 'w', encoding='utf-8') as f:
                    await f.write(json.dumps(self.channel_models, indent=4, ensure_ascii=False))
            except ImportError:
                with open(self.channel_models_path, 'w', encoding='utf-8') as f:
                    json.dump(self.channel_models, f, indent=4, ensure_ascii=False)

            logger.info(f"Saved channel image model settings")
        except Exception as e:
            logger.error(f"Failed to save channel image models: {e}")
            raise

    def _parse_model_string(self, model_string: str) -> tuple[str, str]:
        """
        „É¢„Éá„É´ÊñáÂ≠óÂàó„Çí„Éë„Éº„Çπ„Åó„Å¶ (provider, model_name) „ÇíËøî„Åô
        ‰æã: "huggingface/black-forest-labs/FLUX.1-dev" -> ("huggingface", "black-forest-labs/FLUX.1-dev")
        """
        if '/' not in model_string:
            raise ValueError(f"Invalid model format: {model_string}. Expected 'provider/model_name'")

        parts = model_string.split('/', 1)
        return parts[0], parts[1]

    def get_model_for_channel(self, channel_id: int) -> str:
        """ÊåáÂÆö„Åï„Çå„Åü„ÉÅ„É£„É≥„Éç„É´„Åß‰ΩøÁî®„Åô„Çã„É¢„Éá„É´„ÇíÂèñÂæó"""
        channel_id_str = str(channel_id)
        model = self.channel_models.get(channel_id_str, self.default_model)

        if model not in self.available_models:
            logger.warning(f"Model '{model}' for channel {channel_id} not in available models, using default")
            return self.default_model

        return model

    async def set_model_for_channel(self, channel_id: int, model: str) -> None:
        """ÊåáÂÆö„Åï„Çå„Åü„ÉÅ„É£„É≥„Éç„É´„ÅÆ„É¢„Éá„É´„ÇíË®≠ÂÆö"""
        if model not in self.available_models:
            raise ValueError(f"Model '{model}' is not in available models list")

        channel_id_str = str(channel_id)
        self.channel_models[channel_id_str] = model
        await self._save_channel_models()
        logger.info(f"Set image model for channel {channel_id} to {model}")

    async def reset_model_for_channel(self, channel_id: int) -> bool:
        """ÊåáÂÆö„Åï„Çå„Åü„ÉÅ„É£„É≥„Éç„É´„ÅÆ„É¢„Éá„É´„Çí„Éá„Éï„Ç©„É´„Éà„Å´Êàª„Åô"""
        channel_id_str = str(channel_id)
        if channel_id_str in self.channel_models:
            del self.channel_models[channel_id_str]
            await self._save_channel_models()
            logger.info(f"Reset image model for channel {channel_id} to default")
            return True
        return False

    def get_available_models(self) -> List[str]:
        """Âà©Áî®ÂèØËÉΩ„Å™„É¢„Éá„É´„ÅÆ„É™„Çπ„Éà„ÇíÂèñÂæó"""
        return self.available_models.copy()

    def get_models_by_provider(self) -> Dict[str, List[str]]:
        """„Éó„É≠„Éê„Ç§„ÉÄ„Éº„Åî„Å®„Å´„É¢„Éá„É´„ÇíÂàÜÈ°û„Åó„Å¶Ëøî„Åô"""
        models_by_provider = {}
        for model in self.available_models:
            try:
                provider, _ = self._parse_model_string(model)
                if provider not in models_by_provider:
                    models_by_provider[provider] = []
                models_by_provider[provider].append(model)
            except ValueError:
                continue
        return models_by_provider

    @property
    def name(self) -> str:
        return "generate_image"

    @property
    def tool_spec(self) -> Dict[str, Any]:
        """LLM„Å´Ê∏°„Åô„ÉÑ„Éº„É´ÂÆöÁæ©"""
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": (
                    "Generate an image based on a text prompt using AI image generation. "
                    "Use this when the user asks you to create, generate, or draw an image. "
                    "„É¶„Éº„Ç∂„Éº„ÅåÁîªÂÉè„ÅÆÁîüÊàê„ÄÅ‰ΩúÊàê„ÄÅÊèèÁîª„Çí‰æùÈ†º„Åó„ÅüÊôÇ„Å´„Åì„ÅÆ„ÉÑ„Éº„É´„Çí‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
                ),
                "parameters": {
                    "type": "object",
                    "properties": {
                        "prompt": {
                            "type": "string",
                            "description": (
                                "A detailed description of the image to generate. "
                                "Be specific and descriptive. Include style, mood, colors, etc. "
                                "ÁîüÊàê„Åô„ÇãÁîªÂÉè„ÅÆË©≥Á¥∞„Å™Ë™¨Êòé„ÄÇÂÖ∑‰ΩìÁöÑ„ÅßË©≥Á¥∞„Å´„ÄÇ"
                            )
                        },
                        "negative_prompt": {
                            "type": "string",
                            "description": (
                                "Things to avoid in the image (optional). "
                                "ÁîªÂÉè„Å´Âê´„ÇÅ„Åü„Åè„Å™„ÅÑË¶ÅÁ¥†(„Ç™„Éó„Ç∑„Éß„É≥)„ÄÇ"
                            )
                        },
                        "size": {
                            "type": "string",
                            "description": (
                                "Image size in format WIDTHxHEIGHT (e.g., '1024x1024', '512x768'). "
                                "Default is 1024x1024."
                            ),
                            "enum": ["512x512", "768x768", "1024x1024", "512x768", "768x512"]
                        }
                    },
                    "required": ["prompt"]
                }
            }
        }

    async def run(self, arguments: Dict[str, Any], channel_id: int) -> str:
        """
        ÁîªÂÉèÁîüÊàê„ÇíÂÆüË°å„Åó„ÄÅÁµêÊûú„ÇíËøî„Åô

        Args:
            arguments: „ÉÑ„Éº„É´Âëº„Å≥Âá∫„Åó„ÅÆÂºïÊï∞
            channel_id: Discord„ÉÅ„É£„É≥„Éç„É´id

        Returns:
            LLM„Å´Ëøî„Åô„É¨„Çπ„Éù„É≥„Çπ„É°„ÉÉ„Çª„Éº„Ç∏
        """
        prompt = arguments.get('prompt', '').strip()
        negative_prompt = arguments.get('negative_prompt', '').strip()
        size = arguments.get('size', self.default_size)

        if not prompt:
            return "‚ùå Error: Empty prompt provided. / „Ç®„É©„Éº: „Éó„É≠„É≥„Éó„Éà„ÅåÁ©∫„Åß„Åô„ÄÇ"

        model = self.get_model_for_channel(channel_id)

        logger.info(f"üé® [IMAGE_GEN] Starting image generation")
        logger.info(f"üé® [IMAGE_GEN] Model: {model}, Size: {size}")
        logger.info(f"üé® [IMAGE_GEN] Prompt: {prompt[:100]}...")

        try:
            image_data = await self._generate_image(prompt, negative_prompt, size, model)

            if not image_data:
                return "‚ùå Failed to generate image. / ÁîªÂÉè„ÅÆÁîüÊàê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ"

            channel = self.bot.get_channel(channel_id)
            if not channel:
                logger.error(f"Channel {channel_id} not found!")
                return "‚ùå Error: Could not find channel to send image."

            image_file = discord.File(fp=io.BytesIO(image_data), filename="generated_image.png")

            embed = discord.Embed(
                title="üé® Generated Image / ÁîüÊàê„Åï„Çå„ÅüÁîªÂÉè",
                description=f"**Prompt:** {prompt[:200]}{'...' if len(prompt) > 200 else ''}",
                color=discord.Color.blue()
            )
            if negative_prompt:
                embed.add_field(
                    name="Negative Prompt",
                    value=negative_prompt[:100] + ('...' if len(negative_prompt) > 100 else ''),
                    inline=False
                )
            embed.add_field(name="Size", value=size, inline=True)
            embed.add_field(name="Model", value=model, inline=True)

            try:
                provider, _ = self._parse_model_string(model)
                embed.set_footer(text=f"Provider: {provider}")
            except ValueError:
                pass

            await channel.send(embed=embed, file=image_file)

            logger.info(f"‚úÖ [IMAGE_GEN] Successfully generated and sent image")

            return (
                f"‚úÖ Successfully generated image with prompt: '{prompt[:100]}{'...' if len(prompt) > 100 else ''}'\n"
                f"The image has been sent to the channel. / ÁîªÂÉè„Çí„ÉÅ„É£„É≥„Éç„É´„Å´ÈÄÅ‰ø°„Åó„Åæ„Åó„Åü„ÄÇ"
            )

        except Exception as e:
            logger.error(f"‚ùå [IMAGE_GEN] Error: {e}", exc_info=True)
            return f"‚ùå Error during image generation: {str(e)[:200]}"

    async def _generate_image(
            self,
            prompt: str,
            negative_prompt: str,
            size: str,
            model: str
    ) -> Optional[bytes]:
        """
        ÁîªÂÉè„ÇíÁîüÊàê(„Éó„É≠„Éê„Ç§„ÉÄ„Éº„Åî„Å®„ÅÆÂá¶ÁêÜÂàÜÂ≤ê)

        Args:
            prompt: ÁîüÊàê„Åô„ÇãÁîªÂÉè„ÅÆË™¨Êòé
            negative_prompt: Èô§Â§ñ„Åô„ÇãË¶ÅÁ¥†
            size: ÁîªÂÉè„Çµ„Ç§„Ç∫
            model: ‰ΩøÁî®„Åô„Çã„É¢„Éá„É´(provider/model_nameÂΩ¢Âºè)

        Returns:
            ÁîüÊàê„Åï„Çå„ÅüÁîªÂÉè„Éá„Éº„Çø(PNGÂΩ¢Âºè)
        """
        try:
            provider_name, model_name = self._parse_model_string(model)
        except ValueError as e:
            logger.error(f"‚ùå [IMAGE_GEN] {e}")
            return None

        provider_config = self.image_providers.get(provider_name)
        if not provider_config:
            logger.error(f"‚ùå [IMAGE_GEN] No configuration found for provider: {provider_name}")
            return None

        # API„Ç≠„Éº„ÇíÂèñÂæó - ‰øÆÊ≠£Áâà
        api_key = None

        # „Åæ„ÅöÁõ¥Êé•ÊåáÂÆö„ÅÆapi_key„Çí„ÉÅ„Çß„ÉÉ„ÇØ
        if 'api_key' in provider_config:
            api_key = provider_config['api_key']
            logger.info(f"üîë [IMAGE_GEN] Using direct API key for {provider_name}")
        # Ê¨°„Å´api_key_source„Åã„ÇâÂèñÂæó
        elif 'api_key_source' in provider_config:
            api_key_source = provider_config['api_key_source']
            llm_provider = self.llm_providers.get(api_key_source, {})
            api_key = llm_provider.get('api_key')
            logger.info(f"üîë [IMAGE_GEN] Using API key from llm.providers.{api_key_source}")

        if not api_key:
            logger.error(f"‚ùå [IMAGE_GEN] No API key found for provider: {provider_name}")
            logger.error(f"‚ùå [IMAGE_GEN] Provider config: {provider_config}")
            logger.error(f"‚ùå [IMAGE_GEN] Available LLM providers: {list(self.llm_providers.keys())}")
            return None

        # „Éó„É≠„Éê„Ç§„ÉÄ„Éº„Åî„Å®„Å´Âá¶ÁêÜ„ÇíÂàÜÂ≤ê
        if provider_name == "huggingface":
            return await self._generate_image_huggingface_new(
                api_key, provider_config, model_name, prompt, negative_prompt, size
            )
        elif provider_name == "nvidia_nim":
            return await self._generate_image_nvidia(
                api_key, provider_config, model_name, prompt, negative_prompt, size
            )
        else:
            logger.error(f"‚ùå [IMAGE_GEN] Unsupported provider: {provider_name}")
            return None

    async def _generate_image_huggingface_new(
            self,
            api_key: str,
            provider_config: Dict,
            model_name: str,
            prompt: str,
            negative_prompt: str,
            size: str
    ) -> Optional[bytes]:
        """Hugging Face Inference API„ÅßÁîªÂÉè„ÇíÁîüÊàê (Legacy Inference API‰ΩøÁî®)"""
        width, height = map(int, size.split('x'))

        # Legacy Inference API„Ç®„É≥„Éâ„Éù„Ç§„É≥„ÉàÔºàPOST /models/{model_id}Ôºâ
        url = f"https://api-inference.huggingface.co/models/{model_name}"

        headers = {
            "Authorization": f"Bearer {api_key}",
        }

        # „Éê„Ç§„Éä„É™„Éö„Ç§„É≠„Éº„ÉâÂΩ¢Âºè: JSON„Åß„ÅØ„Å™„Åè„Éó„É≠„É≥„Éó„Éà„ÇíÁõ¥Êé•ÈÄÅ‰ø°
        # ‰∏ÄÈÉ®„É¢„Éá„É´„ÅØJSON„Éë„É©„É°„Éº„Çø„Å´ÂØæÂøú„Åó„Å¶„ÅÑ„Å™„ÅÑ„Åü„ÇÅ„ÄÅ„Ç∑„É≥„Éó„É´„Å™ÂΩ¢Âºè„Çí‰ΩøÁî®
        payload = prompt.encode('utf-8')

        logger.info(f"üîµ [IMAGE_GEN] Calling Hugging Face Legacy Inference API")
        logger.info(f"üîµ [IMAGE_GEN] URL: {url}")
        logger.info(f"üîµ [IMAGE_GEN] Prompt: {prompt[:100]}...")
        logger.info(f"üîµ [IMAGE_GEN] Size: {width}x{height}")

        # Ê≥®ÊÑè: Legacy API„ÅØ‰∏ÄÈÉ®„É¢„Éá„É´„Åßwidth/height„Éë„É©„É°„Éº„Çø„Å´ÂØæÂøú„Åó„Å¶„ÅÑ„Å™„ÅÑ
        # „Åù„ÅÆ„Åü„ÇÅ„ÄÅ„É¢„Éá„É´„ÅÆ„Éá„Éï„Ç©„É´„Éà„Çµ„Ç§„Ç∫„ÅßÁîüÊàê„Åï„Çå„Çã„Åì„Å®„Åå„ÅÇ„Çã

        try:
            async with self.http_session.post(
                    url,
                    headers=headers,
                    data=payload,  # JSON„Åß„ÅØ„Å™„Åè„Éê„Ç§„Éä„É™„Éá„Éº„Çø„Å®„Åó„Å¶ÈÄÅ‰ø°
                    timeout=aiohttp.ClientTimeout(total=self.timeout)
            ) as response:
                logger.info(f"üîµ [IMAGE_GEN] Response status: {response.status}")
                logger.info(f"üîµ [IMAGE_GEN] Response headers: {dict(response.headers)}")

                if response.status == 200:
                    # „É¨„Çπ„Éù„É≥„Çπ„Åå„Éê„Ç§„Éä„É™ÁîªÂÉè„Éá„Éº„Çø
                    content_type = response.headers.get('Content-Type', '')
                    logger.info(f"üîµ [IMAGE_GEN] Content-Type: {content_type}")

                    image_bytes = await response.read()
                    logger.info(f"‚úÖ [IMAGE_GEN] Successfully received image ({len(image_bytes)} bytes)")
                    return image_bytes

                # 503„Ç®„É©„Éº„ÅØ„É¢„Éá„É´„É≠„Éº„Éâ‰∏≠„ÅÆ„Åü„ÇÅ„É™„Éà„É©„Ç§„ÇíË©¶„Åø„Çã
                elif response.status == 503:
                    try:
                        error_json = await response.json()
                        estimated_time = error_json.get('estimated_time', 20.0)
                        logger.warning(f"‚ö†Ô∏è Model is loading. Retrying in {estimated_time} seconds...")
                        await asyncio.sleep(min(estimated_time, 30.0))  # ÊúÄÂ§ß30Áßí„Åæ„Åß
                        # ÂÜçÂ∏∞Âëº„Å≥Âá∫„Åó
                        return await self._generate_image_huggingface_new(
                            api_key, provider_config, model_name, prompt, negative_prompt, size
                        )
                    except Exception as e:
                        logger.error(f"‚ùå [IMAGE_GEN] Error parsing 503 response: {e}")
                        error_text = await response.text()
                        logger.error(f"‚ùå [IMAGE_GEN] 503 Response: {error_text[:500]}")
                        return None

                else:
                    error_text = await response.text()
                    logger.error(f"‚ùå [IMAGE_GEN] API error {response.status}: {error_text[:500]}")

                    # Ë©≥Á¥∞„Å™„Ç®„É©„ÉºÊÉÖÂ†±„ÇíÂá∫Âäõ
                    try:
                        error_json = await response.json()
                        logger.error(f"‚ùå [IMAGE_GEN] Error details: {error_json}")
                    except:
                        pass

                    return None

        except asyncio.TimeoutError:
            logger.error(f"‚ùå [IMAGE_GEN] Request timed out after {self.timeout}s")
            return None
        except Exception as e:
            logger.error(f"‚ùå [IMAGE_GEN] Exception during API call: {e}", exc_info=True)
            return None

    async def _generate_image_nvidia(
            self,
            api_key: str,
            provider_config: Dict,
            model_name: str,
            prompt: str,
            negative_prompt: str,
            size: str
    ) -> Optional[bytes]:
        """NVIDIA NIM API„ÅßÁîªÂÉè„ÇíÁîüÊàê"""
        width, height = map(int, size.split('x'))
        base_url = provider_config.get('base_url', 'https://integrate.api.nvidia.com/v1')
        base_url = base_url.rstrip('/')
        url = f"{base_url}/images/generations"

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
            "Accept": "application/json"
        }

        payload = {
            "model": model_name,
            "text_prompts": [{"text": prompt, "weight": 1.0}],
            "cfg_scale": 5.0,
            "sampler": "K_DPM_2_ANCESTRAL",
            "seed": 0,
            "steps": 25,
            "width": width,
            "height": height
        }

        if negative_prompt:
            payload["text_prompts"].append({"text": negative_prompt, "weight": -1.0})

        logger.info(f"üîµ [IMAGE_GEN] Calling NVIDIA NIM API")
        logger.info(f"üîµ [IMAGE_GEN] URL: {url}")

        try:
            async with self.http_session.post(
                    url,
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=self.timeout)
            ) as response:
                logger.info(f"üîµ [IMAGE_GEN] Response status: {response.status}")

                if response.status == 200:
                    result = await response.json()

                    if result.get('artifacts') and len(result['artifacts']) > 0:
                        b64_image = result['artifacts'][0].get('base64')
                        if b64_image:
                            image_bytes = base64.b64decode(b64_image)
                            logger.info(f"‚úÖ [IMAGE_GEN] Successfully received image ({len(image_bytes)} bytes)")
                            return image_bytes

                    logger.error(f"‚ùå [IMAGE_GEN] No image data in response")
                    return None
                else:
                    error_text = await response.text()
                    logger.error(f"‚ùå [IMAGE_GEN] API error {response.status}: {error_text[:500]}")
                    return None

        except asyncio.TimeoutError:
            logger.error(f"‚ùå [IMAGE_GEN] Request timed out after {self.timeout}s")
            return None
        except Exception as e:
            logger.error(f"‚ùå [IMAGE_GEN] Exception: {e}", exc_info=True)
            return None

    async def close(self):
        """HTTP„Çª„ÉÉ„Ç∑„Éß„É≥„Çí„ÇØ„É≠„Éº„Ç∫"""
        await self.http_session.close()
        logger.info("ImageGenerator HTTP session closed")