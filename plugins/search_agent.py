from __future__ import annotations
import asyncio
import logging
from typing import Dict, Any, Optional, List
import json

# ãƒ­ã‚°ã®åˆæœŸåŒ–ã‚’æœ€åˆã«è¡Œã†
logger = logging.getLogger(__name__)

# MistralAIã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã‚ˆã£ã¦exceptionsãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™
try:
    from mistralai.async_client import MistralAsyncClient
    from mistralai.exceptions import MistralAPIException
    from mistralai.models.chat_completion import ChatMessage, ChatCompletionResponse
except ImportError:
    try:
        from mistralai import MistralAsyncClient

        MistralAPIException = Exception
        logger.warning("MistralAI exceptions module not found, using generic Exception")
    except ImportError:
        logger.error("MistralAI library not found. Please install: pip install mistralai")
        MistralAsyncClient = None
        MistralAPIException = Exception


class SearchAgent:

    name = "search"
    tool_spec = {
        "type": "function",
        "function": {
            "name": name,
            "description": "Run a web search using the Mistral AI search tool and return a comprehensive report.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The search query to execute"
                    }
                },
                "required": ["query"],
            },
        },
    }

    # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹æ¤œç´¢å¯¾å¿œãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆ
    SUPPORTED_MODELS = [
        "mistral-large-latest",
        "mistral-large-2407",
        "mistral-large-2411",
        "mistral-medium-2505"
    ]

    def __init__(self, bot) -> None:
        self.bot = bot
        self.client: Optional[MistralAsyncClient] = None
        self.model = "mistral-large-latest"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«
        self.max_retries = 3
        self.base_delay = 1.0
        self.timeout = 30.0
        self.initialization_error = None

        try:
            # config.yamlã®ã‚­ãƒ¼ 'search_agent' ã‚’å‚ç…§ã—ã¾ã™
            logger.info("Loading configuration...")
            mcfg = self.bot.cfg.get("search_agent", {})
            logger.info(f"Configuration loaded: {list(mcfg.keys())}")

            api_key = mcfg.get("api_key")

            if not api_key:
                error_msg = "API key not found in configuration under 'search_agent.api_key'"
                logger.error(error_msg)
                logger.error("Please add the following to your config.yaml:")
                logger.error("search_agent:")
                logger.error("api_key: 'your_mistral_api_key_here'")
                logger.error("model: 'mistral-large-latest'")
                self.initialization_error = error_msg
                return

            # API keyã®é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚æœ€åˆã®æ•°æ–‡å­—ã®ã¿è¡¨ç¤ºï¼‰
            logger.info(f"API key found (starts with: {api_key[:8]}...)")

            # è¨­å®šã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ã€ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            configured_model = mcfg.get("model", "mistral-large-latest")
            if configured_model in self.SUPPORTED_MODELS:
                self.model = configured_model
                logger.info(f"Using configured model: {self.model}")
            else:
                logger.warning(f"Model '{configured_model}' may not support search. Using default: {self.model}")

            # ãã®ä»–ã®è¨­å®š
            self.max_retries = mcfg.get("max_retries", 3)
            self.base_delay = mcfg.get("base_delay", 1.0)
            self.timeout = mcfg.get("timeout", 30.0)

        except Exception as e:
            error_msg = f"Failed to initialize MistralAsyncClient for SearchAgent: {e}"
            logger.error(error_msg, exc_info=True)
            self.initialization_error = error_msg
            self.client = None

    async def _mistral_search(self, query: str) -> str:

        if not self.client:
            error_details = []
            error_details.append("API client is not initialized. Check configuration and logs.")

            if self.initialization_error:
                error_details.append(f"Initialization error: {self.initialization_error}")

            if MistralAsyncClient is None:
                error_details.append("MistralAI library not installed. Run: pip install mistralai")

            # è¨­å®šã®è¨ºæ–­
            try:
                mcfg = self.bot.cfg.get("search_agent", {})
                if not mcfg:
                    error_details.append("No 'search_agent' configuration found in config.yaml")
                else:
                    api_key = mcfg.get("api_key")
                    if not api_key:
                        error_details.append("No 'api_key' found in search_agent configuration")
                    else:
                        error_details.append(f"API key present (length: {len(api_key)})")
            except Exception as e:
                error_details.append(f"Error checking configuration: {e}")

            return "[Mistral Search Error]\n" + "\n".join(error_details)

        if not query.strip():
            return "[Mistral Search Error]\nEmpty query provided."

        for attempt in range(self.max_retries + 1):
            try:
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å½¢å¼ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
                messages = [
                    {
                        "role": "user",
                        "content": f"Please search for information about: {query}\n\nProvide a comprehensive summary of the search results including key findings, relevant details, and sources when available."
                    }
                ]

                logger.debug(f"Mistral Search attempt {attempt + 1}: {query}")

                # éåŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ãƒãƒ£ãƒƒãƒˆã‚’å®Ÿè¡Œ
                response = await asyncio.wait_for(
                    self.client.chat(
                        model=self.model,
                        messages=messages,
                        tool_choice="search",
                        temperature=0.1,  # ã‚ˆã‚Šä¸€è²«ã—ãŸçµæœã®ãŸã‚ã«ä½ã‚ã®æ¸©åº¦ã‚’è¨­å®š
                        max_tokens=4000,  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æœ€å¤§é•·ã‚’åˆ¶é™
                    ),
                    timeout=self.timeout
                )

                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å†…å®¹ã‚’å–å¾—
                if response.choices and len(response.choices) > 0:
                    message = response.choices[0].message

                    if message.content:
                        # çµæœã®å‰å‡¦ç†
                        content = message.content.strip()
                        if content:
                            logger.info(f"Mistral Search successful for query: {query}")
                            return self._format_search_result(content, query)
                        else:
                            logger.warning("Empty content received from Mistral API")
                            return "[Mistral Search Error]\nEmpty response content received."
                    else:
                        logger.warning("No content in message from Mistral API")
                        return "[Mistral Search Error]\nNo content received from the API."
                else:
                    logger.warning("No response choices received from Mistral API")
                    return "[Mistral Search Error]\nNo response choices received from the API."

            except asyncio.TimeoutError:
                logger.warning(f"Mistral Search timeout on attempt {attempt + 1}")
                if attempt < self.max_retries:
                    await asyncio.sleep(self.base_delay * (2 ** attempt))
                    continue
                return f"[Mistral Search Error]\nRequest timeout after {self.timeout}s. Please try again."

            except Exception as e:
                error_message = str(e)
                logger.error(f"Mistral API error on attempt {attempt + 1}: {error_message}")

                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãƒã‚§ãƒƒã‚¯
                if self._is_rate_limit_error(error_message):
                    msg = "Rate limit encountered. Please wait and try again."
                    logger.warning(f"Mistral Search: {msg}")
                    return f"[Mistral Search Error]\n{msg}"

                # ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ã®ãƒã‚§ãƒƒã‚¯
                if self._is_server_error(error_message) and attempt < self.max_retries:
                    delay = self.base_delay * (2 ** attempt)
                    logger.warning(f"Mistral Search: Server error detected. Retrying in {delay}s...")
                    await asyncio.sleep(delay)
                    continue

                # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
                if attempt < self.max_retries:
                    delay = self.base_delay * (2 ** attempt)
                    logger.info(f"Retrying after API error... (attempt {attempt + 1}/{self.max_retries}) in {delay}s")
                    await asyncio.sleep(delay)
                    continue

                return f"[Mistral Search Error]\nAPI error: {error_message}"

        return "[Mistral Search Error]\nFailed to get a response after several retries."

    def _is_rate_limit_error(self, error_message: str) -> bool:
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        rate_limit_indicators = ["429", "rate limit", "too many requests"]
        return any(indicator in error_message.lower() for indicator in rate_limit_indicators)

    def _is_server_error(self, error_message: str) -> bool:
        """ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        server_error_codes = ["500", "502", "503", "504"]
        return any(code in error_message for code in server_error_codes)

    def _format_search_result(self, content: str, query: str) -> str:
        """æ¤œç´¢çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹"""
        try:
            # åŸºæœ¬çš„ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            formatted_result = f"ğŸ” **Search Results for: {query}**\n\n"
            formatted_result += content

            # çµæœã®é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ã«å¿œã˜ã¦åˆ‡ã‚Šè©°ã‚ã‚‹
            if len(formatted_result) > 3500:  # å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³ã‚’è€ƒæ…®
                formatted_result = formatted_result[:3500] + "\n\n[Results truncated due to length limit]"

            return formatted_result

        except Exception as e:
            logger.error(f"Error formatting search result: {e}")
            return content  # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿”ã™

    async def run(self, *, arguments: Dict[str, Any], bot) -> str:
        """
        The main entry point for the agent, called by the LLM cog.

        Args:
            arguments: Dictionary containing the query and other parameters
            bot: The bot instance

        Returns:
            str: The search results or error message
        """
        try:
            query = arguments.get("query", "").strip()
            if not query:
                return "[Mistral Search Error] The 'query' argument is empty or invalid."

            logger.info(f"SearchAgent executing query: {query}")
            result = await self._mistral_search(query)
            logger.info("SearchAgent completed successfully")
            return result

        except Exception as e:
            logger.error(f"Unexpected error in SearchAgent's run method: {e}", exc_info=True)
            return f"[Mistral Search Error]\nUnexpected error in run method: {e}"

    def is_available(self) -> bool:
        """
        Check if the SearchAgent is properly configured and available.

        Returns:
            bool: True if the agent is available, False otherwise
        """
        return self.client is not None

    def get_status(self) -> Dict[str, Any]:
        """
        Get the current status of the SearchAgent.

        Returns:
            dict: Status information including configuration and availability
        """
        status = {
            "available": self.is_available(),
            "model": self.model,
            "supported_models": self.SUPPORTED_MODELS,
            "max_retries": self.max_retries,
            "timeout": self.timeout,
            "client_initialized": self.client is not None,
            "initialization_error": self.initialization_error,
            "mistral_library_available": MistralAsyncClient is not None
        }

        # è¨­å®šã®è¨ºæ–­
        try:
            mcfg = self.bot.cfg.get("search_agent", {})
            status["config_present"] = bool(mcfg)
            status["api_key_present"] = bool(mcfg.get("api_key"))
            if mcfg.get("api_key"):
                status["api_key_length"] = len(mcfg.get("api_key"))
        except Exception as e:
            status["config_error"] = str(e)

        return status

    def get_diagnostic_info(self) -> str:
        """
        Get detailed diagnostic information as a formatted string.

        Returns:
            str: Formatted diagnostic information
        """
        status = self.get_status()
        lines = []
        lines.append("=== SearchAgent Diagnostic Information ===")

        for key, value in status.items():
            lines.append(f"{key}: {value}")

        lines.append("")
        lines.append("=== Required Setup ===")
        lines.append("1. Install MistralAI library: pip install mistralai")
        lines.append("2. Add to config.yaml:")
        lines.append("  search_agent:")
        lines.append("  api_key: 'your_mistral_api_key'")
        lines.append("  model: 'mistral-large-latest'")
        lines.append("3. Get API key from: https://console.mistral.ai/")

        return "\n".join(lines)

    async def test_connection(self) -> tuple[bool, str]:
        """
        Test the connection to the Mistral API.

        Returns:
            tuple: (success: bool, message: str)
        """
        if not self.client:
            return False, "Client not initialized"

        try:
            # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
            test_result = await self._mistral_search("test connection")
            if "[Mistral Search Error]" in test_result:
                return False, test_result
            return True, "Connection test successful"
        except Exception as e:
            return False, f"Connection test failed: {e}"